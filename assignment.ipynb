{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment\n",
        "Lidewij Hollestelle, Lisanne de Bruin, Lucas Piret and Amber van Teijnlingen\n",
        "\n",
        "Group 7, GIST and non-GIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and analyse data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel 'base (Python 3.10.9)' due to a timeout waiting for the ports to get used. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell performs the following tasks:\n",
        "1. Imports necessary libraries and sets a random state for reproducibility.\n",
        "2. Loads the dataset using the `load_data` function and separates it into features (`values`) and labels (`labels`).\n",
        "3. Converts categorical labels ('GIST' and 'non-GIST') into numeric values (1 and 0).\n",
        "4. Performs a Shapiro-Wilk test to count the number of features that are not normally distributed.\n",
        "5. Generates a heatmap to visualize the correlation matrix of the features using Spearman's correlation.\n",
        "6. Randomly selects 24 features and creates scatter plots for 12 pairs of features to analyze linearity.\n",
        "\"\"\"\n",
        "\n",
        "# Import libraries\n",
        "from load_data import load_data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from scipy.stats import shapiro\n",
        "import random\n",
        "\n",
        "# Initialize random state for reproducibility\n",
        "rand_state = 42\n",
        "\n",
        "# Load the dataset and print some information\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Seperate the labels from the values\n",
        "labels = data['label']\n",
        "values = data.drop(columns=['label'])\n",
        "\n",
        "# Convert 'GIST' and 'non-GIST' to numeric values\n",
        "labels = labels.map({'GIST': 1, 'non-GIST': 0})\n",
        "\n",
        "# Perform Shapiro-Wilk test for normality on each feature\n",
        "# and count the number of features that are not normally distributed\n",
        "counter = 0\n",
        "for feature in values.columns:\n",
        "    stat, p_value = shapiro(values[feature])\n",
        "    if p_value < 0.05:\n",
        "        counter += 1\n",
        "print(f'The number of features that are not normally distributed: {counter}')\n",
        "\n",
        "# Heatmap for the entire correlation matrix\n",
        "correlation_matrix = values.corr(method='spearman').abs()\n",
        "plt.figure(figsize=(15, 15)) \n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", cbar_kws={'label': 'Correlation Coefficient'})\n",
        "plt.show()\n",
        "\n",
        "# Randomly select 24 features for scatter plots to visualize the data\n",
        "random.seed(rand_state)\n",
        "random_features = random.sample(list(values.columns), 24)\n",
        "\n",
        "# Create a 3x4 subplot\n",
        "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Plot each pair of features\n",
        "for i in range(0, 24, 2):\n",
        "    feature_x = random_features[i]\n",
        "    feature_y = random_features[i + 1]\n",
        "    ax = axes[i // 2]\n",
        "    ax.scatter(values[feature_x], values[feature_y], alpha=0.5)\n",
        "    ax.set_xlabel(feature_x, fontsize=8)\n",
        "    ax.set_ylabel(feature_y, fontsize=8)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature selection and dimension reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This cell defines two functions for preprocessing and feature selection:\n",
        "\n",
        "1. preprocess_train_test(training_values, test_values):\n",
        "    - Handles missing values by replacing them with the mean of the training data.\n",
        "    - Standardizes the training and testing data using RobustScaler.\n",
        "    - Removes features with low variance using VarianceThreshold.\n",
        "\n",
        "2. statistical_selection(values, labels):\n",
        "    - Fits a logistic regression model for each feature to compute its p-value.\n",
        "    - Removes highly correlated features based on Spearman's correlation and p-values.\n",
        "    - Returns the dataset with selected features.\n",
        "\"\"\"\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from statsmodels import api as sm\n",
        "\n",
        "def preprocess_train_test(training_values, test_values):\n",
        "    \"\"\"\n",
        "    Preprocesses the training and testing datasets by handling missing values, standardizing the data, \n",
        "    and removing features with low variance.\n",
        "\n",
        "    Args:\n",
        "        training_values (pd.DataFrame): The training dataset with features.\n",
        "        test_values (pd.DataFrame): The testing dataset with features.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame, pd.DataFrame: The preprocessed training and testing datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    # First we remove NaNs by averaging\n",
        "    training_values = training_values.fillna(training_values.mean())\n",
        "    test_values = test_values.fillna(training_values.mean())\n",
        "\n",
        "    # Standardize the training & testing data separately\n",
        "    scaler = RobustScaler()\n",
        "    scaled_training_values = scaler.fit_transform(training_values)\n",
        "\n",
        "    training_values = pd.DataFrame(scaled_training_values, columns=training_values.columns, index=training_values.index)\n",
        "\n",
        "    scaled_test_values = scaler.transform(test_values)\n",
        "    test_values = pd.DataFrame(scaled_test_values, columns=test_values.columns, index=test_values.index)\n",
        "\n",
        "    # Remove features with zero variance\n",
        "    selector = VarianceThreshold(threshold=0.3) \n",
        "\n",
        "    training_non_zero_var = selector.fit_transform(training_values)\n",
        "    training_values = pd.DataFrame(training_non_zero_var, columns=training_values.columns[selector.get_support()], index=training_values.index)\n",
        "\n",
        "    test_non_zero_var = selector.transform(test_values)\n",
        "    test_values = pd.DataFrame(test_non_zero_var, columns=test_values.columns[selector.get_support()], index=test_values.index)\n",
        "\n",
        "    return training_values, test_values\n",
        "\n",
        "def statistical_selection(values, labels):\n",
        "    # Now we can run the logistic regression model for each feature to get its correlation with the label\n",
        "    p_values = {}\n",
        "\n",
        "    for column in values.columns:\n",
        "        logit_model = sm.Logit(labels, values[column])\n",
        "        result = logit_model.fit(disp = False)\n",
        "\n",
        "        p_values[column] = result.pvalues[column]\n",
        "\n",
        "    # Now we remove highly correlated features\n",
        "    # Make a correlation matrix to analyse the correlation between the features\n",
        "    correlation_matrix = values.corr(method = 'spearman').abs()\n",
        "\n",
        "    features_to_remove = []\n",
        "\n",
        "    for feature1 in correlation_matrix.columns:\n",
        "        for feature2 in correlation_matrix.columns:\n",
        "            if feature1 != feature2 and feature1 not in features_to_remove and feature2 not in features_to_remove:\n",
        "                if correlation_matrix[feature1][feature2] > 0.90:\n",
        "                    # Remove the feature with the higher p-value\n",
        "                    if p_values[feature1] > p_values[feature2]:\n",
        "                        features_to_remove.append(feature1)\n",
        "                    else:\n",
        "                        features_to_remove.append(feature2)\n",
        "\n",
        "    values = values.drop(columns=features_to_remove)\n",
        "    \n",
        "    # Remove the features from p_values as well\n",
        "    #for feature in features_to_remove:\n",
        "    #    del p_values[feature]\n",
        "\n",
        "    # Select the top 30 features with the lowest p-values\n",
        "    #sorted_features = sorted(p_values, key=p_values.get)[:30]\n",
        "    #values = values[sorted_features]\n",
        "\n",
        "    return values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "import numpy as np\n",
        "\n",
        "# Make learning\n",
        "def plot_learning_curve(model, training_data, training_labels, cv, model_name):    \n",
        "    train_sizes, train_scores, validation_scores = learning_curve(\n",
        "        model, training_data, training_labels, cv=cv, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)\n",
        "    )\n",
        "\n",
        "    # Calculate the mean and standard deviation of the scores\n",
        "    train_mean = train_scores.mean(axis=1)\n",
        "    validation_mean = validation_scores.mean(axis=1)\n",
        "    train_std = train_scores.std(axis=1)\n",
        "    validation_std = validation_scores.std(axis=1)\n",
        "\n",
        "    # Plot the learning curve\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_sizes, train_mean, label=\"Training score\", color=\"r\")\n",
        "    plt.plot(train_sizes, validation_mean, label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"r\", alpha=0.2)\n",
        "    plt.fill_between(train_sizes, validation_mean - validation_std, validation_mean + validation_std, color=\"g\", alpha=0.2)\n",
        "\n",
        "    # Adding labels and title\n",
        "    plt.xlabel(\"Training Size\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.3, 1.01)\n",
        "    plt.title(f\"Learning Curve for {model_name}\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def logistic_regression(training_values, training_labels):\n",
        "    elastic_net = LogisticRegressionCV(\n",
        "        solver='saga',\n",
        "        penalty='elasticnet',\n",
        "        Cs=[1, 10, 100],\n",
        "        l1_ratios=[0.8],\n",
        "        max_iter=10000,\n",
        "        cv=5,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    print('Start')\n",
        "    elastic_net.fit(training_values, training_labels)\n",
        "\n",
        "    #sfs = SequentialFeatureSelector(elastic_net, n_features_to_select=30, direction='forward', n_jobs=-1, scoring = 'accuracy')\n",
        "    #sfs.fit(training_values, training_labels)\n",
        "\n",
        "    #selected_indices = sfs.get_support(indices=True)\n",
        "    #selected_features = training_values.iloc[:, selected_indices]\n",
        "   \n",
        "    #cv_scores = cross_val_score(elastic_net, selected_features, training_labels, cv=5, scoring = 'accuracy')\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "\n",
        "    scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc'\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "        estimator=elastic_net,\n",
        "        X=training_values,\n",
        "        y=training_labels,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    #plot_learning_curve(elastic_net, training_values, training_labels, cv, 'Logistic regression')\n",
        "\n",
        "    selected_features = np.where(elastic_net.coef_ != 0)[0]\n",
        "\n",
        "    print(f\"{len(selected_features)} features selected out of {len(training_values.columns)}\")\n",
        "\n",
        "    training_values = training_values.iloc[:, selected_features]\n",
        "\n",
        "    return elastic_net, cv_scores, training_values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def train_random_forest(training_values, training_labels):\n",
        "    # Initialize the Random Forest Classifier\n",
        "    param_grid = {\n",
        "        'n_estimators': randint(1, 100),\n",
        "        'max_depth': randint(1, 30),\n",
        "        'max_features': ['sqrt', 'log2'],\n",
        "        'min_samples_leaf': randint(1, 10)\n",
        "        }\n",
        "    \n",
        "    random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_grid, n_iter=100, cv=5, n_jobs=-1, random_state=rand_state)\n",
        "\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Return best model's cross-validation score\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    #sfs = SequentialFeatureSelector(best_model, n_features_to_select=30, direction='forward', n_jobs=-1, scoring = 'accuracy')\n",
        "    #sfs.fit(training_values, training_labels)\n",
        "\n",
        "    #selected_indices = sfs.get_support(indices=True)\n",
        "    #selected_features = training_values.iloc[:, selected_indices]\n",
        "   \n",
        "    #cv_scores = cross_val_score(best_model, selected_features, training_labels, cv=5, scoring = 'accuracy')\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "\n",
        "    scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc'\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "        estimator=best_model,\n",
        "        X=training_values,\n",
        "        y=training_labels,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    return best_model, cv_scores\n",
        "\n",
        "    \"\"\"\n",
        "    feature_importances = best_model.feature_importances_\n",
        "\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': training_values.columns,\n",
        "        'Importance': feature_importances\n",
        "    })\n",
        "\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
        "\n",
        "    all_scores = []\n",
        "    for i in range(1, 493):\n",
        "        top_features = feature_importance_df.head(i)['Feature'].values\n",
        "\n",
        "        data_selected = training_values[top_features]\n",
        "        labels_selected = training_labels\n",
        "\n",
        "        final_model = best_model.fit(data_selected, labels_selected)\n",
        "        cv_scores = cross_val_score(final_model, data_selected, labels_selected, cv=5)\n",
        "        all_scores.append(cv_scores.mean())\n",
        "\n",
        "    # Plot the cross-validation scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, 493), all_scores, marker='o', linestyle='-', color='b')\n",
        "    plt.xlabel('Number of Top Features')\n",
        "    plt.ylabel('Cross-Validation Accuracy')\n",
        "    plt.title('Random Forest Number of Included Top Features')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KNN-classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def KNN(training_values, training_labels):\n",
        "    param_grid = {\n",
        "    'n_neighbors': list(range(1, 26)),\n",
        "    'weights': ['uniform', 'distance']\n",
        "    }\n",
        "\n",
        "    random_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Return best model's cross-validation score\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    #sfs = SequentialFeatureSelector(best_model, n_features_to_select=30, direction='forward', n_jobs=-1, scoring = 'accuracy')\n",
        "    #sfs.fit(training_values, training_labels)\n",
        "\n",
        "    #selected_indices = sfs.get_support(indices=True)\n",
        "    #selected_features = training_values.iloc[:, selected_indices]\n",
        "   \n",
        "    #cv_scores = cross_val_score(best_model, selected_features, training_labels, cv=5, scoring = 'accuracy')\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "\n",
        "    scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc'\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "        estimator=best_model,\n",
        "        X=training_values,\n",
        "        y=training_labels,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "\n",
        "    return best_model, cv_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def SVM(training_values, training_labels):\n",
        "    param_grid = {\n",
        "        'C': [0.1, 0.5, 1, 5, 10, 25], \n",
        "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "        'gamma': ['scale', 0.01, 0.1, 1],\n",
        "        'degree': [2, 3, 4],\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(SVC(), param_distributions=param_grid,n_iter=100, cv=5, n_jobs=-1, random_state=rand_state)\n",
        "\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Return best model's cross-validation score\n",
        "    best_model = random_search.best_estimator_\n",
        "    print(best_model)\n",
        "\n",
        "    #sfs = SequentialFeatureSelector(best_model, n_features_to_select=30, direction='forward', n_jobs=-1, scoring = 'accuracy')\n",
        "    #sfs.fit(training_values, training_labels)\n",
        "\n",
        "    #selected_indices = sfs.get_support(indices=True)\n",
        "    #selected_features = training_values.iloc[:, selected_indices]\n",
        "   \n",
        "    #cv_scores = cross_val_score(best_model, selected_features, training_labels, cv=5, scoring = 'accuracy')\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "\n",
        "    scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc'\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "        estimator=best_model,\n",
        "        X=training_values,\n",
        "        y=training_labels,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    return best_model, cv_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try the different classifiers for 5 different folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# 5-fold cross-validation setup\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "# Create a dataframe to store the results\n",
        "cross_val_results = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(values, labels)):\n",
        "    print(f\"\\n=== Fold {fold} ===\")\n",
        "\n",
        "    training_values = values.iloc[train_index]\n",
        "    training_labels = labels[train_index]\n",
        "\n",
        "    test_values = values.iloc[test_index]\n",
        "    test_labels = labels[test_index]\n",
        "\n",
        "    training_values, test_values = preprocess_train_test(training_values, test_values)\n",
        "\n",
        "    #training_values = statistical_selection(training_values, training_labels)\n",
        "\n",
        "    print(training_values.shape)\n",
        "\n",
        "    # Now train the classifiers\n",
        "\n",
        "    logit_model, logit_score, selected_values = logistic_regression(training_values, training_labels)\n",
        "    print(f\"Fold {fold} - Logistic Regression Score: {logit_score['test_accuracy'].mean()}\")\n",
        "\n",
        "    forest_model, forest_score = train_random_forest(training_values, training_labels)\n",
        "    print(f\"Fold {fold} - Random Forest Score: {forest_score['test_accuracy'].mean()}\")\n",
        "\n",
        "    KNN_model, knn_score = KNN(training_values, training_labels)\n",
        "    print(f\"Fold {fold} - KNN Score: {knn_score['test_accuracy'].mean()}\")\n",
        "\n",
        "    SVM_model, svm_score = SVM(training_values, training_labels)\n",
        "    print(f\"Fold {fold} - SVM Score: {svm_score['test_accuracy'].mean()}\")\n",
        "\n",
        "    # Append scores for each model\n",
        "    cross_val_results.append({'Model': logit_model, 'Fold': fold, 'Precision': logit_score['test_precision'].mean(), 'Recall': logit_score['test_recall'].mean(), 'Accuracy': logit_score['test_accuracy'].mean(), 'ROC AUC': logit_score['test_roc_auc'].mean()})\n",
        "    cross_val_results.append({'Model': forest_model, 'Fold': fold, 'Precision': forest_score['test_precision'].mean(), 'Recall': forest_score['test_recall'].mean(), 'Accuracy': forest_score['test_accuracy'].mean(), 'ROC AUC': forest_score['test_roc_auc'].mean()})\n",
        "    cross_val_results.append({'Model': KNN_model, 'Fold': fold, 'Precision': knn_score['test_precision'].mean(), 'Recall': knn_score['test_recall'].mean(), 'Accuracy': knn_score['test_accuracy'].mean(), 'ROC AUC': knn_score['test_roc_auc'].mean()})\n",
        "    cross_val_results.append({'Model': SVM_model, 'Fold': fold, 'Precision': svm_score['test_precision'].mean(), 'Recall': svm_score['test_recall'].mean(), 'Accuracy': svm_score['test_accuracy'].mean(), 'ROC AUC': svm_score['test_roc_auc'].mean()})\n",
        "\n",
        "\n",
        "# Convert the results list to a dataframe\n",
        "results_df = pd.DataFrame(cross_val_results)\n",
        "\n",
        "results_df.to_csv('cross_val_results.csv', index=False)\n",
        "\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
