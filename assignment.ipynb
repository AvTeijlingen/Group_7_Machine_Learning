{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CiDn2Sk-VWqE"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and analyse data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 246\n",
            "The number of columns: 494\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 246 entries, GIST-001_0 to GIST-246_0\n",
            "Columns: 494 entries, label to PREDICT_original_phasef_phasesym_entropy_WL3_N5\n",
            "dtypes: float64(468), int64(25), object(1)\n",
            "memory usage: 951.3+ KB\n",
            "None\n",
            "The number of features that are not normally distributed: 443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lisan\\anaconda3\\lib\\site-packages\\scipy\\stats\\_morestats.py:1797: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
            "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
          ]
        }
      ],
      "source": [
        "from load_data import load_data\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import sns\n",
        "import pandas as pd\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "# Code used to load the original data and split into train and test set\n",
        "# Was only run once at the start to create test and train dataset\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Seperate the labels from the values\n",
        "labels = data['label']\n",
        "values = data.drop(columns=['label'])\n",
        "\n",
        "# Convert 'GIST' and 'non-GIST' to numeric values\n",
        "labels = labels.map({'GIST': 1, 'non-GIST': 0})\n",
        "\n",
        "counter = 0\n",
        "for feature in values.columns:\n",
        "    stat, p_value = shapiro(values[feature])\n",
        "    if p_value < 0.05:\n",
        "        counter += 1\n",
        "print(f'The number of features that are not normally distributed: {counter}')\n",
        "\n",
        "# Heatmap for the entire correlation matrix (for large datasets, consider reducing the size)\n",
        "correlation_matrix = values.corr().abs()\n",
        "plt.figure(figsize=(15, 15))  # Adjust size as needed\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", cbar_kws={'label': 'Correlation Coefficient'})\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature selection and dimension reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Now we can run the logistic regression model for each feature to get its correlation with the label\\np_values = {}\\n\\nfor column in values.columns:\\n    logit_model = sm.Logit(labels, values[column])\\n    result = logit_model.fit()\\n\\n    p_values[column] = result.pvalues[column]\\n\\nprint(p_values)\\n\\n# Now we remove highly correlated features\\n# Make a correlation matrix to analyse the correlation between the features\\ncorrelation_matrix = values.corr().abs()\\n\\n# Heatmap for the entire correlation matrix (for large datasets, consider reducing the size)\\nplt.figure(figsize=(15, 15))  # Adjust size as needed\\nsns.heatmap(correlation_matrix, annot=False, cmap=\\'coolwarm\\', fmt=\".2f\", cbar_kws={\\'label\\': \\'Correlation Coefficient\\'})\\nplt.show()\\n\\nfeatures_to_remove = []\\n\\nfor feature1 in correlation_matrix.columns:\\n    for feature2 in correlation_matrix.columns:\\n        if feature1 != feature2 and feature1 not in features_to_remove and feature2 not in features_to_remove:\\n            if correlation_matrix[feature1][feature2] > 0.90:\\n                # Remove the feature with the higher p-value\\n                if p_values[feature1] < p_values[feature2]:\\n                    features_to_remove.append(feature1)\\n                else:\\n                    features_to_remove.append(feature2)\\n\\nvalues = values.drop(columns=features_to_remove)\\n\\ncorrelation_matrix_2 = values.corr().abs()\\n\\n# Heatmap for the entire correlation matrix (for large datasets, consider reducing the size)\\nplt.figure(figsize=(15, 15))  # Adjust size as needed\\nsns.heatmap(correlation_matrix_2, annot=False, cmap=\\'coolwarm\\', fmt=\".2f\", cbar_kws={\\'label\\': \\'Correlation Coefficient\\'})\\nplt.show()\\n'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocess_train_test(training_values, test_values):\n",
        "    # First we remove NaNs by averaging\n",
        "    training_values = training_values.fillna(training_values.mean())\n",
        "    test_values = test_values.fillna(training_values.mean())\n",
        "\n",
        "   # Remove features with zero variance\n",
        "   # Initialize the VarianceThreshold selector\n",
        "    selector = VarianceThreshold(threshold=0) \n",
        "\n",
        "    # Fit the selector on the training data\n",
        "    training_non_zero_var = selector.fit_transform(training_values)\n",
        "    training_values = pd.DataFrame(training_non_zero_var, columns=training_values.columns[selector.get_support()], index=training_values.index)\n",
        "\n",
        "    # Apply the same transformation to the test data\n",
        "    test_non_zero_var = selector.transform(test_values)\n",
        "    test_values = pd.DataFrame(test_non_zero_var, columns=test_values.columns[selector.get_support()], index=test_values.index)\n",
        "\n",
        "    # Standardize the training & testing data separately\n",
        "    scaler = StandardScaler()\n",
        "    scaled_training_values = scaler.fit_transform(training_non_zero_var)\n",
        "\n",
        "    training_values = pd.DataFrame(scaled_training_values, columns=training_values.columns, index=training_values.index)\n",
        "\n",
        "    scaled_test_values = scaler.transform(test_non_zero_var)\n",
        "    test_values = pd.DataFrame(scaled_test_values, columns=test_values.columns, index=test_values.index)\n",
        "\n",
        "    return training_values, test_values\n",
        "\n",
        "\"\"\"\n",
        "# Now we can run the logistic regression model for each feature to get its correlation with the label\n",
        "p_values = {}\n",
        "\n",
        "for column in values.columns:\n",
        "    logit_model = sm.Logit(labels, values[column])\n",
        "    result = logit_model.fit()\n",
        "\n",
        "    p_values[column] = result.pvalues[column]\n",
        "\n",
        "print(p_values)\n",
        "\n",
        "# Now we remove highly correlated features\n",
        "# Make a correlation matrix to analyse the correlation between the features\n",
        "correlation_matrix = values.corr().abs()\n",
        "\n",
        "features_to_remove = []\n",
        "\n",
        "for feature1 in correlation_matrix.columns:\n",
        "    for feature2 in correlation_matrix.columns:\n",
        "        if feature1 != feature2 and feature1 not in features_to_remove and feature2 not in features_to_remove:\n",
        "            if correlation_matrix[feature1][feature2] > 0.90:\n",
        "                # Remove the feature with the higher p-value\n",
        "                if p_values[feature1] < p_values[feature2]:\n",
        "                    features_to_remove.append(feature1)\n",
        "                else:\n",
        "                    features_to_remove.append(feature2)\n",
        "\n",
        "values = values.drop(columns=features_to_remove)\n",
        "\n",
        "correlation_matrix_2 = values.corr().abs()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Elastic net selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def logistic_regression(training_values, training_labels):\n",
        "    param_grid = {\n",
        "        'Cs': [1, 10, 100],  # Regularization strength\n",
        "        'l1_ratios': [0.1, 0.5, 0.8],  # Elastic net mixing parameter\n",
        "        'max_iter': [1000, 5000]  # Maximum number of iterations\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(\n",
        "        LogisticRegressionCV(), param_distributions=param_grid, n_iter=50, cv=5, n_jobs=-1\n",
        "    )\n",
        "\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    best_params = random_search.best_params_\n",
        "    print(f\"Best hyperparameters found: {best_params}\")\n",
        "\n",
        "    elastic_net = random_search.best_estimator_\n",
        "\n",
        "    cv_scores = cross_val_score(elastic_net, training_values, training_labels, cv=5)\n",
        "\n",
        "    selected_features = np.where(elastic_net.coef_ != 0)[0]\n",
        "\n",
        "    print(f\"{len(selected_features)} features selected out of {len(training_values.columns)}\")\n",
        "\n",
        "    training_values = training_values.iloc[:, selected_features]\n",
        "\n",
        "    return cv_scores.mean(), training_values\n",
        "\n",
        "## ALSO: code voor sequential feature selection\n",
        "#sfs = SequentialFeatureSelector(model, n_features_to_select=10, direction='forward', n_jobs=-1)\n",
        "#sfs.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "def train_random_forest(training_values, training_labels):\n",
        "    # Initialize the Random Forest Classifier\n",
        "    param_grid = {\n",
        "        'n_estimators': randint(1, 100),\n",
        "        'max_depth': randint(1, 30),\n",
        "        'max_features': ['sqrt', 'log2'],\n",
        "        'min_samples_leaf': randint(1, 10)\n",
        "        }\n",
        "    \n",
        "    random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_grid, n_iter=100, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Return best model's cross-validation score\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    feature_importances = best_model.feature_importances_\n",
        "\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': training_values.columns,\n",
        "        'Importance': feature_importances\n",
        "    })\n",
        "\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
        "\n",
        "    all_scores = []\n",
        "    for i in range(1, 493):\n",
        "        top_features = feature_importance_df.head(i)['Feature'].values\n",
        "\n",
        "        data_selected = training_values[top_features]\n",
        "        labels_selected = training_labels\n",
        "\n",
        "        final_model = best_model.fit(data_selected, labels_selected)\n",
        "        cv_scores = cross_val_score(best_model, data_selected, labels_selected, cv=5)\n",
        "        all_scores.append(cv_scores.mean())\n",
        "\n",
        "    # Plot the cross-validation scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, 493), all_scores, marker='o', linestyle='-', color='b')\n",
        "    plt.xlabel('Number of Top Features')\n",
        "    plt.ylabel('Cross-Validation Accuracy')\n",
        "    plt.title('Random Forest Number of Included Top Features')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return final_model, cv_scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KNN-classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "def KNN(training_values, training_labels):\n",
        "    #training_values, training_labels = elastic_net_feature_selection(training_values, training_labels)\n",
        "\n",
        "    param_grid = {\n",
        "    'n_neighbors': randint(1, 100),\n",
        "    'weights': ['uniform', 'distance']\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_grid, n_iter=20, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Return best model's cross-validation score\n",
        "    best_model = random_search.best_estimator_\n",
        "    print(best_model)\n",
        "    cv_scores = cross_val_score(best_model, training_values, training_labels, cv=5)\n",
        "\n",
        "    return cv_scores.mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.svm import SVC\n",
        "# from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
        "\n",
        "# def SVM(training_values, training_labels):\n",
        "#     #training_values, training_labels = elastic_net_feature_selection(training_values, training_labels)\n",
        "\n",
        "#     param_grid = {\n",
        "#         'C': [0.1,0.5,1,5,10,25,50], # Use a wide range of slacks\n",
        "#         'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], # the used kernels\n",
        "#         'gamma': ['scale', 'auto', 0.01, 0.1, 1],  # SLack variable per object \n",
        "#         'degree': [2, 3, 4],  # Only used for 'poly' kernel\n",
        "#     }\n",
        "\n",
        "#     random_search = RandomizedSearchCV(SVC(), param_distributions=param_grid,n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "#     random_search.fit(training_values, training_labels)\n",
        "#     print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "#     # Return best model's cross-validation score\n",
        "#     best_model = random_search.best_estimator_\n",
        "#     print(best_model)\n",
        "#     cv_scores = cross_val_score(best_model, training_values, training_labels, cv=5)\n",
        "\n",
        "    # return cv_scores.mean()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def SVM(training_values, training_labels):\n",
        "    clf = SVC()\n",
        "\n",
        "    # Define hyperparameters\n",
        "    param_grid = {\n",
        "        'C': [0.1, 0.5, 1, 5, 10, 25, 50], \n",
        "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "        'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
        "        'degree': [2, 3, 4],\n",
        "    }\n",
        "\n",
        "    # Optimize model with n_iter=100 to find best hyperparameters\n",
        "    random_search = RandomizedSearchCV(\n",
        "        clf, param_distributions=param_grid, n_iter=100, cv=5, n_jobs=-1, random_state=42\n",
        "    )\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    best_params = random_search.best_params_\n",
        "    print(f\"Best hyperparameters found: {best_params}\")\n",
        "\n",
        "    # Look at the performance with different iteration values\n",
        "    iterations = [10, 20, 30, 40, 50, 75, 100]\n",
        "    scores = []\n",
        "\n",
        "    for i in iterations:\n",
        "\n",
        "        random_search_iter = RandomizedSearchCV(\n",
        "            clf, param_distributions=param_grid, n_iter=i, cv=5, n_jobs=-1, random_state=42\n",
        "        )\n",
        "\n",
        "        random_search_iter.fit(training_values, training_labels)\n",
        "        best_model = random_search_iter.best_estimator_\n",
        "        cv_score = cross_val_score(best_model, training_values, training_labels, cv=5).mean()\n",
        "        \n",
        "        scores.append(cv_score)\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(iterations, scores, marker='o', linestyle='-', color='b', label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Number of Iterations\")\n",
        "    plt.ylabel(\"Cross-Validation Accuracy\")\n",
        "    plt.title(\"SVM Performance vs. Number of Iterations\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    train_sizes, train_scores, validation_scores = learning_curve(\n",
        "        best_model, training_values, training_labels, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)\n",
        "    )\n",
        "\n",
        "    # Calculate the mean and standard deviation of the scores\n",
        "    train_mean = train_scores.mean(axis=1)\n",
        "    validation_mean = validation_scores.mean(axis=1)\n",
        "    train_std = train_scores.std(axis=1)\n",
        "    validation_std = validation_scores.std(axis=1)\n",
        "\n",
        "    # Plot the learning curve\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_sizes, train_mean, label=\"Training score\", color=\"r\")\n",
        "    plt.plot(train_sizes, validation_mean, label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"r\", alpha=0.2)\n",
        "    plt.fill_between(train_sizes, validation_mean - validation_std, validation_mean + validation_std, color=\"g\", alpha=0.2)\n",
        "\n",
        "    # Adding labels and title\n",
        "    plt.xlabel(\"Training Size\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.3, 1.01)\n",
        "    plt.title(\"Learning Curve for SVM\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return cv_score.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear classifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def linear_classifier(training_values,training_labels):\n",
        "    # First we do a PCA\n",
        "    pca = PCA(n_components=2)  # You can set n_components to the number of components you want\n",
        "    principal_components = pca.fit_transform(training_values)\n",
        "\n",
        "    # Step 3: Create a DataFrame of principal components\n",
        "    pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2']) \n",
        "\n",
        "    # Plot the two principal components against each other\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(pca_df['PC1'], pca_df['PC2'], alpha=0.7, c=training_labels, cmap='viridis')\n",
        "    plt.xlabel('Principal Component 1')\n",
        "    plt.ylabel('Principal Component 2')\n",
        "    plt.title('PCA: Principal Component 1 vs Principal Component 2')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # # === LDA model trainen ===\n",
        "    param_grid = {\n",
        "        'solver': ['lsqr', 'eigen'],  # Solver types for LDA\n",
        "        'shrinkage': [None, 'auto'],  # Shrinkage types for LDA\n",
        "    }\n",
        "\n",
        "    random_search = RandomizedSearchCV(LinearDiscriminantAnalysis(), param_distributions=param_grid,n_iter=4, cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "    random_search.fit(pca_df, training_labels)\n",
        "    print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Return best model's cross-validation score\n",
        "    best_model = random_search.best_estimator_\n",
        "    print(best_model)\n",
        "    cv_scores = cross_val_score(best_model, training_values, training_labels, cv=5)\n",
        "    \n",
        "    return cv_scores.mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try the different classifiers for 5 different folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Fold 0 ===\n",
            "Best hyperparameters: {'max_depth': 8, 'max_features': 'sqrt', 'min_samples_leaf': 9, 'n_estimators': 62}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# 5-fold cross-validation setup\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(values, labels)):\n",
        "    print(f\"\\n=== Fold {fold} ===\")\n",
        "\n",
        "    training_values = values.iloc[train_index]\n",
        "    training_labels = labels[train_index]\n",
        "\n",
        "    test_values = values.iloc[test_index]\n",
        "    test_labels = labels[test_index]\n",
        "\n",
        "    training_values, test_values = preprocess_train_test(training_values, test_values)\n",
        "\n",
        "    # Now train the classifiers\n",
        "\n",
        "    forest_model, forest_score = train_random_forest(training_values, training_labels)\n",
        "    print(f\"Fold {fold} - Random Forest Score: {forest_score:.4f}\")\n",
        "\n",
        "    #knn_score = KNN(training_values, training_labels)\n",
        "    #print(f\"Fold {fold} - KNN Score: {knn_score:.4f}\")\n",
        "\n",
        "    #svm_score = SVM(training_values, training_labels)\n",
        "    #print(f\"Fold {fold} - SVM Score: {svm_score:.4f}\")\n",
        "\n",
        "    lda_score = linear_classifier(training_values, training_labels)\n",
        "    print(f\"Fold {fold} - LDA Score: {lda_score:.4f}\")\n",
        "\n",
        "    selected_feature, logit_score = logistic_regression(training_values, training_labels)\n",
        "    print(f\"Fold {fold} - Logistic Regression Score: {logit_score:.4f}\")\n",
        "    \n",
        "#)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
