{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment - GIST & non-GIST\n",
        "Lidewij Hollestelle, Lisanne de Bruin, Lucas Piret and Amber van Teijlingen \n",
        "\n",
        "Group 7, GIST and non-GIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "#!git clone https://github.com/AvTeijlingen/Group_7_Machine_Learning.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File location adapted to the colab environment\n",
        "# If you are using a different environment, please change the file location accordingly\n",
        "def load_data():\n",
        "    data = pd.read_csv('Group_7_Machine_Learning/GIST_radiomicFeatures.csv', index_col = 0)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and analyse data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Group_7_Machine_Learning/GIST_radiomicFeatures.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[89], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m rand_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10007\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Load the dataset and print some information\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[88], line 6\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m():\n\u001b[1;32m----> 6\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGroup_7_Machine_Learning/GIST_radiomicFeatures.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[1;32mc:\\Users\\lisan\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lisan\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\lisan\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lisan\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\lisan\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Group_7_Machine_Learning/GIST_radiomicFeatures.csv'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell performs the following tasks:\n",
        "- Imports necessary libraries and sets a random state for reproducibility.\n",
        "- Loads the dataset using the `load_data` function and separates it into features (`values`) and labels (`labels`).\n",
        "- Converts categorical labels ('GIST' and 'non-GIST') into numeric values (1 and 0).\n",
        "- Performs a Shapiro-Wilk test to count the number of features that are not normally distributed.\n",
        "- Generates a heatmap to visualize the correlation matrix of the features using Spearman's correlation.\n",
        "\"\"\"\n",
        "\n",
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "# Initialize random state for reproducibility\n",
        "rand_state = 10007\n",
        "\n",
        "# Load the dataset and print some information\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Seperate the labels from the values\n",
        "labels = data['label']\n",
        "values = data.drop(columns=['label'])\n",
        "\n",
        "# Convert 'GIST' and 'non-GIST' to numeric values\n",
        "labels = labels.map({'GIST': 1, 'non-GIST': 0})\n",
        "\n",
        "# Perform Shapiro-Wilk test for normality on each feature\n",
        "# and count the number of features that are not normally distributed\n",
        "counter = 0\n",
        "for feature in values.columns:\n",
        "    stat, p_value = shapiro(values[feature])\n",
        "    if p_value < 0.05:\n",
        "        counter += 1\n",
        "print(f'The number of features that are not normally distributed: {counter}')\n",
        "\n",
        "# Heatmap for the entire correlation matrix\n",
        "correlation_matrix = values.corr(method='spearman').abs()\n",
        "plt.figure(figsize=(15, 15)) \n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", cbar_kws={'label': 'Correlation Coefficient'})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature selection and dimension reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndef perform_PCA(values):\\n    pca = decomposition.PCA(n_components=30)\\n    pca.fit(values)\\n    training_values_pca = pca.transform(values)\\n\\n    # Now, create the DataFrame with new column names (for the PCA components)\\n    training_values = pd.DataFrame(training_values_pca, \\n                                columns=[f'PC{i+1}' for i in range(training_values_pca.shape[1])], \\n                                index=values.index)\\n    return training_values\\n\""
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell defines two functions for preprocessing and feature selection:\n",
        "\n",
        "1. preprocess_train_test(training_values, test_values):\n",
        "    - In case of missing values, replaces them with the mean of the training data.\n",
        "    - Standardizes the training and testing data using RobustScaler.\n",
        "    - Removes features with low variance using VarianceThreshold.\n",
        "\n",
        "2. statistical_selection(values, labels):\n",
        "    - Fits a logistic regression model for each feature to compute its p-value.\n",
        "    - Removes highly correlated features based on Spearman's correlation and p-values.\n",
        "    - Returns the dataset with selected features.\n",
        "\"\"\"\n",
        "\n",
        "# Import libraries\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from statsmodels import api as sm\n",
        "\n",
        "def preprocess_train_test(training_values, test_values):\n",
        "    \"\"\"\n",
        "    Preprocesses the training and testing datasets by handling missing values, standardizing the data, \n",
        "    and removing features with low variance.\n",
        "\n",
        "    Args:\n",
        "        training_values (pd.DataFrame): The training dataset with features.\n",
        "        test_values (pd.DataFrame): The testing dataset with features.\n",
        "\n",
        "    Returns:\n",
        "        training_values (pd.DataFrame), test_values (pd.DataFrame): The preprocessed training and testing datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    # First we remove NaNs by averaging\n",
        "    training_values = training_values.fillna(training_values.mean())\n",
        "    test_values = test_values.fillna(training_values.mean())\n",
        "\n",
        "    # Standardize the training & testing data separately and turn them into DataFrames\n",
        "    scaler = RobustScaler()\n",
        "    scaled_training_values = scaler.fit_transform(training_values)\n",
        "    training_values = pd.DataFrame(scaled_training_values, columns=training_values.columns, index=training_values.index)\n",
        "\n",
        "    scaled_test_values = scaler.transform(test_values)\n",
        "    test_values = pd.DataFrame(scaled_test_values, columns=test_values.columns, index=test_values.index)\n",
        "\n",
        "    # Remove features with low variance and turn them into DataFrames\n",
        "    selector = VarianceThreshold(threshold=0.3) \n",
        "\n",
        "    training_low_var = selector.fit_transform(training_values)\n",
        "    training_values = pd.DataFrame(training_low_var, columns=training_values.columns[selector.get_support()], index=training_values.index)\n",
        "\n",
        "    test_low_var = selector.transform(test_values)\n",
        "    test_values = pd.DataFrame(test_low_var, columns=test_values.columns[selector.get_support()], index=test_values.index)\n",
        "\n",
        "    return training_values, test_values\n",
        "\n",
        "def statistical_selection(values, labels, k=None):\n",
        "    \"\"\"\n",
        "    Remove highly correlated features.\n",
        "    Keeps only the features with the lowest p-values from univariate logistic regression.\n",
        "    If k is not None, selects the top k features based on the lowest p-value.\n",
        "\n",
        "    Args:\n",
        "        values (pd.DataFrame): The dataset containing features.\n",
        "        labels (pd.Series): The target labels corresponding to the dataset.\n",
        "        k (int, optional): The number of top features to select based on p-values. If None, all features are retained.\n",
        "\n",
        "    Returns:\n",
        "        values (pd.DataFrame), labels (pd.Index): The dataset with selected features and the names of the selected features.\n",
        "    \"\"\"\n",
        "\n",
        "    # Now we perform univariate logistic regression to get the correlation of the features with the label\n",
        "    p_values = {}\n",
        "\n",
        "    for column in values.columns:\n",
        "        logit_model = sm.Logit(labels, values[column])\n",
        "        result = logit_model.fit(disp = False)\n",
        "\n",
        "        p_values[column] = result.pvalues[column]\n",
        "\n",
        "    # Remove highly correlated values\n",
        "    correlation_matrix = values.corr(method = 'spearman').abs()\n",
        "\n",
        "    features_to_remove = []\n",
        "\n",
        "    # Loop through all combinations of features\n",
        "    for feature1 in correlation_matrix.columns:\n",
        "        for feature2 in correlation_matrix.columns:\n",
        "            # If they are not the same feature and not already marked for removal\n",
        "            if feature1 != feature2 and feature1 not in features_to_remove and feature2 not in features_to_remove:\n",
        "                # Check if the features are highly correlated\n",
        "                if correlation_matrix[feature1][feature2] > 0.90:\n",
        "                    # Remove the feature with the higher p-value\n",
        "                    if p_values[feature1] > p_values[feature2]:\n",
        "                        features_to_remove.append(feature1)\n",
        "                    else:\n",
        "                        features_to_remove.append(feature2)\n",
        "\n",
        "    # Remove the features that are marked for removal\n",
        "    values = values.drop(columns=features_to_remove)\n",
        "    \n",
        "    # If k was specified, select the top k features\n",
        "    if k:\n",
        "        # Remove the features from p_values as well\n",
        "        for feature in features_to_remove:\n",
        "            del p_values[feature]\n",
        "\n",
        "        # Select the top k features with the lowest p-values\n",
        "        sorted_features = sorted(p_values, key=p_values.get)[:k]\n",
        "        values = values[sorted_features]\n",
        "\n",
        "    return values, values.columns\n",
        "\n",
        "# Code to perform PCA on the dataset\n",
        "\"\"\"\n",
        "def perform_PCA(values):\n",
        "    pca = decomposition.PCA(n_components=30)\n",
        "    pca.fit(values)\n",
        "    training_values_pca = pca.transform(values)\n",
        "\n",
        "    # Now, create the DataFrame with new column names (for the PCA components)\n",
        "    training_values = pd.DataFrame(training_values_pca, \n",
        "                                columns=[f'PC{i+1}' for i in range(training_values_pca.shape[1])], \n",
        "                                index=values.index)\n",
        "    return training_values\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from sklearn.model_selection import learning_curve\n",
        "import numpy as np\n",
        "\n",
        "# Make learning curve plots for the models\n",
        "def plot_learning_curve(model, training_data, training_labels, cv, model_name): \n",
        "    \"\"\"\n",
        "    This cell defines a function to plot the learning curve of a given model.\n",
        "\n",
        "    The function `plot_learning_curve`:\n",
        "    - Computes the learning curve for a model using cross-validation.\n",
        "    - Plots the training and cross-validation scores as a function of the training size.\n",
        "    - Includes shaded regions to represent the standard deviation of the scores.\n",
        "\n",
        "    Args:\n",
        "        model: The machine learning model to evaluate.\n",
        "        training_data (pd.DataFrame): The training dataset with features.\n",
        "        training_labels (pd.Series): The target labels corresponding to the training dataset.\n",
        "        cv: Cross-validation strategy (e.g., StratifiedKFold).\n",
        "        model_name (str): Name of the model for the plot title.\n",
        "\n",
        "    Returns:\n",
        "        None. Displays the learning curve plot.\n",
        "    \"\"\"   \n",
        "    train_sizes, train_scores, validation_scores = learning_curve(\n",
        "        model, training_data, training_labels, cv=cv, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)\n",
        "    )\n",
        "\n",
        "    # Calculate the mean and standard deviation of the scores\n",
        "    train_mean = train_scores.mean(axis=1)\n",
        "    validation_mean = validation_scores.mean(axis=1)\n",
        "    train_std = train_scores.std(axis=1)\n",
        "    validation_std = validation_scores.std(axis=1)\n",
        "\n",
        "    # Plot the learning curve\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_sizes, train_mean, label=\"Training score\", color=\"r\")\n",
        "    plt.plot(train_sizes, validation_mean, label=\"Cross-validation score\", color=\"g\")\n",
        "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"r\", alpha=0.2)\n",
        "    plt.fill_between(train_sizes, validation_mean - validation_std, validation_mean + validation_std, color=\"g\", alpha=0.2)\n",
        "\n",
        "    # Adding labels and title\n",
        "    plt.xlabel(\"Training Size\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.ylim(0.3, 1.01)\n",
        "    plt.title(f\"Learning Curve for {model_name}\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def plot_roc(probs, test_labels, model_name, fold):\n",
        "    \"\"\"\n",
        "    Plots the ROC curve for a model on a given fold.\n",
        "\n",
        "    Parameters:\n",
        "        probs (list): List of predicted probabilities for the positive class.\n",
        "        test_labels (list): True labels for the test set.\n",
        "        model_name (str): Name of the model for the title. \n",
        "        fold_number (int): Fold number.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute ROC curve and AUC\n",
        "    fpr, tpr, _ = roc_curve(test_labels, probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    plt.title(f'ROC Curve - {model_name} (Fold {fold})')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def logistic_regression(training_values, training_labels):\n",
        "    \"\"\"\n",
        "    Perform logistic regression with elastic net regularization.\n",
        "\n",
        "    Args:\n",
        "        training_values (pd.DataFrame): The training dataset with features.\n",
        "        training_labels (pd.Series): The target labels corresponding to the training dataset.\n",
        "\n",
        "    Returns:\n",
        "        elastic_net (LogisticRegressionCV): The trained logistic regression model with elastic net regularization.\n",
        "        cv_scores (dict): Cross-validation scores for precision, recall, accuracy, and ROC AUC.\n",
        "        training_values (pd.DataFrame): The training dataset with selected features based on non-zero coefficients.\n",
        "    \"\"\"\n",
        "    # Set up the cross-validation strategy\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "\n",
        "    # Perform logistic regression with elastic net regularization\n",
        "    elastic_net = LogisticRegressionCV(\n",
        "        solver='saga',\n",
        "        penalty='elasticnet',\n",
        "        Cs=[1, 10, 100],\n",
        "        l1_ratios=[0.8],\n",
        "        max_iter=10000,\n",
        "        cv=cv,\n",
        "        n_jobs=-1,\n",
        "        random_state = rand_state\n",
        "    )\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    elastic_net.fit(training_values, training_labels)\n",
        "\n",
        "    # Print the best hyperparameters\n",
        "    #print(elastic_net.C_)\n",
        "\n",
        "    # Evaluate the model using cross-validation\n",
        "    scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc'\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "        estimator=elastic_net,\n",
        "        X=training_values,\n",
        "        y=training_labels,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Plot learning curve\n",
        "    #plot_learning_curve(elastic_net, training_values, training_labels, cv, 'Logistic regression')\n",
        "\n",
        "    # Select features based on non-zero coefficients\n",
        "    selected_features = np.where(elastic_net.coef_ != 0)[0]\n",
        "\n",
        "    #print(f\"{len(selected_features)} features selected out of {len(training_values.columns)}\")\n",
        "\n",
        "    training_values = training_values.iloc[:, selected_features]\n",
        "\n",
        "    return elastic_net, cv_scores, training_values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def train_random_forest(training_values, training_labels):\n",
        "    \"\"\"\n",
        "    Trains a Random Forest Classifier using RandomizedSearchCV for hyperparameter tuning.\n",
        "\n",
        "    Args:\n",
        "        training_values (pd.DataFrame): The training dataset with features.\n",
        "        training_labels (pd.Series): The target labels corresponding to the training dataset.\n",
        "\n",
        "    Returns:\n",
        "        best_model (RandomForestClassifier): The trained Random Forest model with the best hyperparameters.\n",
        "        cv_scores (dict): Cross-validation scores for precision, recall, accuracy, and ROC AUC.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize grid\n",
        "    param_grid = {\n",
        "        'n_estimators': randint(1, 100),\n",
        "        'max_depth': randint(1, 30),\n",
        "        'max_features': ['sqrt', 'log2'],\n",
        "        'min_samples_leaf': randint(1, 10)\n",
        "        }\n",
        "    \n",
        "    # Set up the cross-validation strategy\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "    \n",
        "    # Perform RandomizedSearchCV for hyperparameter tuning\n",
        "    random_search = RandomizedSearchCV(RandomForestClassifier(random_state=rand_state), param_distributions=param_grid, n_iter=100, cv=cv, n_jobs=-1, random_state=rand_state)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    #print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Evaluate the model using cross-validation\n",
        "    scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc'\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "        estimator=best_model,\n",
        "        X=training_values,\n",
        "        y=training_labels,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Plot learning curve\n",
        "    #plot_learning_curve(best_model, training_values, training_labels, cv, 'Random Forest')\n",
        "\n",
        "    return best_model, cv_scores\n",
        "\n",
        "    # This code was used to determine the number of features to include in the model based on random forest feature importances.\n",
        "    # It was commented out because it was not used in the final model selection, and was computationally expensive.\n",
        "    \"\"\"\n",
        "    feature_importances = best_model.feature_importances_\n",
        "\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': training_values.columns,\n",
        "        'Importance': feature_importances\n",
        "    })\n",
        "\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
        "\n",
        "    all_scores = []\n",
        "    for i in range(1, 493):\n",
        "        top_features = feature_importance_df.head(i)['Feature'].values\n",
        "\n",
        "        data_selected = training_values[top_features]\n",
        "        labels_selected = training_labels\n",
        "\n",
        "        final_model = best_model.fit(data_selected, labels_selected)\n",
        "        cv_scores = cross_val_score(final_model, data_selected, labels_selected, cv=5)\n",
        "        all_scores.append(cv_scores.mean())\n",
        "\n",
        "    # Plot the cross-validation scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, 493), all_scores, marker='o', linestyle='-', color='b')\n",
        "    plt.xlabel('Number of Top Features')\n",
        "    plt.ylabel('Cross-Validation Accuracy')\n",
        "    plt.title('Random Forest Number of Included Top Features')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KNN-classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def KNN(training_values, training_labels):\n",
        "    \"\"\"\n",
        "    Trains a K-Nearest Neighbors (KNN) classifier using GridSearchCV for hyperparameter tuning.\n",
        "\n",
        "    Args:\n",
        "        training_values (pd.DataFrame): The training dataset with features.\n",
        "        training_labels (pd.Series): The target labels corresponding to the training dataset.\n",
        "\n",
        "    Returns:\n",
        "        best_model (KNeighborsClassifier): The trained KNN model with the best hyperparameters.\n",
        "        cv_scores (dict): Cross-validation scores for precision, recall, accuracy, and ROC AUC.\n",
        "    \"\"\"\n",
        "    # Initialize grid\n",
        "    param_grid = {\n",
        "    'n_neighbors': list(range(1, 26)),\n",
        "    'weights': ['uniform', 'distance']\n",
        "    }\n",
        "\n",
        "    # Set up the cross-validation strategy\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "\n",
        "    # Perform GridSearchCV for hyperparameter tuning\n",
        "    random_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=cv, n_jobs=-1)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    #print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Evaluate the model using cross-validation\n",
        "    scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc'\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "        estimator=best_model,\n",
        "        X=training_values,\n",
        "        y=training_labels,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    # Plot learning curve\n",
        "    #plot_learning_curve(best_model, training_values, training_labels, cv, 'KNN')\n",
        "\n",
        "    return best_model, cv_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def SVM(training_values, training_labels):\n",
        "    \"\"\"\n",
        "    Trains a Support Vector Machine (SVM) classifier using GridSearchCV for hyperparameter tuning.\n",
        "\n",
        "    Args:\n",
        "        training_values (pd.DataFrame): The training dataset with features.\n",
        "        training_labels (pd.Series): The target labels corresponding to the training dataset.\n",
        "\n",
        "    Returns:\n",
        "        best_model (SVC): The trained SVM model with the best hyperparameters.\n",
        "        cv_scores (dict): Cross-validation scores for precision, recall, accuracy, and ROC AUC.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize grid\n",
        "    param_grid = {\n",
        "        'C': [0.1, 0.5, 1, 5], \n",
        "        'kernel': ['linear', 'rbf'],\n",
        "        'gamma': ['scale', 0.01, 0.1, 1],\n",
        "    }\n",
        "\n",
        "    # Set up the cross-validation strategy\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "    \n",
        "    # Perform GridSearchCV for hyperparameter tuning\n",
        "    random_search = GridSearchCV(SVC(probability=True), param_grid, cv=cv, n_jobs=-1)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    random_search.fit(training_values, training_labels)\n",
        "    #print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Evaluate the model using cross-validation\n",
        "    scoring = {\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'accuracy': 'accuracy',\n",
        "    'roc_auc': 'roc_auc'\n",
        "    }\n",
        "\n",
        "    cv_scores = cross_validate(\n",
        "        estimator=best_model,\n",
        "        X=training_values,\n",
        "        y=training_labels,\n",
        "        cv=cv,\n",
        "        scoring=scoring,\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    # Plot learning curve\n",
        "    #plot_learning_curve(best_model, training_values, training_labels, cv, 'SVM')\n",
        "\n",
        "    return best_model, cv_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try the different classifiers for 5 different folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Fold 0 ===\n",
            "Fold 0 - Logistic Regression Score: 0.6126923076923076\n",
            "Best hyperparameters: {'max_depth': 9, 'max_features': 'log2', 'min_samples_leaf': 9, 'n_estimators': 67}\n",
            "Fold 0 - Random Forest Score: 0.6683333333333333\n",
            "Best hyperparameters: {'n_neighbors': 8, 'weights': 'distance'}\n",
            "Fold 0 - KNN Score: 0.6328205128205128\n",
            "Best hyperparameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Fold 0 - SVM Score: 0.6533333333333333\n",
            "\n",
            "=== Fold 1 ===\n",
            "Fold 1 - Logistic Regression Score: 0.6753846153846153\n",
            "Best hyperparameters: {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'n_estimators': 46}\n",
            "Fold 1 - Random Forest Score: 0.706025641025641\n",
            "Best hyperparameters: {'n_neighbors': 14, 'weights': 'uniform'}\n",
            "Fold 1 - KNN Score: 0.6701282051282051\n",
            "Best hyperparameters: {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Fold 1 - SVM Score: 0.6757692307692308\n",
            "\n",
            "=== Fold 2 ===\n",
            "Fold 2 - Logistic Regression Score: 0.6348717948717949\n",
            "Best hyperparameters: {'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 56}\n",
            "Fold 2 - Random Forest Score: 0.6957692307692308\n",
            "Best hyperparameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
            "Fold 2 - KNN Score: 0.6205128205128204\n",
            "Best hyperparameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Fold 2 - SVM Score: 0.6398717948717949\n",
            "\n",
            "=== Fold 3 ===\n",
            "Fold 3 - Logistic Regression Score: 0.6803846153846154\n",
            "Best hyperparameters: {'max_depth': 23, 'max_features': 'log2', 'min_samples_leaf': 4, 'n_estimators': 62}\n",
            "Fold 3 - Random Forest Score: 0.6856410256410257\n",
            "Best hyperparameters: {'n_neighbors': 25, 'weights': 'uniform'}\n",
            "Fold 3 - KNN Score: 0.6598717948717949\n",
            "Best hyperparameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Fold 3 - SVM Score: 0.6655128205128206\n",
            "\n",
            "=== Fold 4 ===\n",
            "Fold 4 - Logistic Regression Score: 0.6957692307692308\n",
            "Best hyperparameters: {'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 66}\n",
            "Fold 4 - Random Forest Score: 0.7108974358974359\n",
            "Best hyperparameters: {'n_neighbors': 17, 'weights': 'uniform'}\n",
            "Fold 4 - KNN Score: 0.7006410256410256\n",
            "Best hyperparameters: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Fold 4 - SVM Score: 0.726025641025641\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
        "\n",
        "# Set up 5-fold cross validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
        "\n",
        "# Create a dataframe to store the results\n",
        "cross_val_results = []\n",
        "test_results = []\n",
        "\n",
        "# Loop through each fold\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(values, labels)):\n",
        "    print(f\"\\n=== Fold {fold} ===\")\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    training_values = values.iloc[train_index]\n",
        "    training_labels = labels.iloc[train_index]\n",
        "\n",
        "    test_values = values.iloc[test_index]\n",
        "    test_labels = labels.iloc[test_index]\n",
        "\n",
        "    # Perform preprocessing\n",
        "    training_values, test_values = preprocess_train_test(training_values, test_values)\n",
        "\n",
        "    # This code was used to determine the number of features to include in the model based on statistical selection.\n",
        "    # We selected values ranging from 1 to 50 to train each model to determine the best number of features.\n",
        "    \"\"\"\n",
        "    #accuracies_logit = []\n",
        "    #accuracies_forest = []\n",
        "    #accuracies_knn = []\n",
        "    #accuracies_SVM = []\n",
        "\n",
        "    #for k in range(1, 50, 2):\n",
        "    \"\"\"\n",
        "\n",
        "    # Perform statistical selection\n",
        "    training_values_chosen, remaining_features = statistical_selection(training_values, training_labels, 10)\n",
        "    # Also select the same features from the test set\n",
        "    test_values = test_values[remaining_features]\n",
        "\n",
        "\n",
        "    # Now we train and evaluate each classifier\n",
        "    # Logistic Regression\n",
        "    logit_model, logit_score, selected_values = logistic_regression(training_values_chosen, training_labels)\n",
        "    print(f\"Fold {fold} - Logistic Regression Score: {logit_score['test_accuracy'].mean()}\")\n",
        "    #accuracies_logit.append(logit_score['test_accuracy'].mean())\n",
        "    # Append to cross validation training scores\n",
        "    cross_val_results.append({'Model': logit_model, 'Fold': fold, 'Precision': logit_score['test_precision'].mean(), 'Recall': logit_score['test_recall'].mean(), 'Accuracy': logit_score['test_accuracy'].mean(), 'ROC AUC': logit_score['test_roc_auc'].mean()})\n",
        "\n",
        "    # Predict on the test data\n",
        "    logit_test_predictions = logit_model.predict(test_values)\n",
        "    logit_test_probabilities = logit_model.predict_proba(test_values)[:, 1]\n",
        "\n",
        "    # Calculate metrics of test data\n",
        "    test_results.append({'Model': logit_model, 'Fold': fold, 'Precision':  precision_score(test_labels, logit_test_predictions), 'Recall': recall_score(test_labels, logit_test_predictions),\n",
        "                         'Accuracy': accuracy_score(test_labels, logit_test_predictions), 'ROC AUC': roc_auc_score(test_labels, logit_test_probabilities)})\n",
        "\n",
        "    # Plot ROC curve\n",
        "    #plot_roc(logit_test_probabilities, test_labels, 'Logistic Regression', fold)\n",
        "\n",
        "\n",
        "    # Random forest\n",
        "    forest_model, forest_score = train_random_forest(training_values_chosen, training_labels)\n",
        "    print(f\"Fold {fold} - Random Forest Score: {forest_score['test_accuracy'].mean()}\")\n",
        "    #accuracies_forest.append(forest_score['test_accuracy'].mean())\n",
        "    # Append to cross validation training scores\n",
        "    cross_val_results.append({'Model': forest_model, 'Fold': fold, 'Precision': forest_score['test_precision'].mean(), 'Recall': forest_score['test_recall'].mean(), 'Accuracy': forest_score['test_accuracy'].mean(), 'ROC AUC': forest_score['test_roc_auc'].mean()})\n",
        "\n",
        "    # Predict on the test data\n",
        "    forest_test_predictions = forest_model.predict(test_values)\n",
        "    forest_test_probabilities = forest_model.predict_proba(test_values)[:, 1]\n",
        "\n",
        "    # Calculate metrics of test data\n",
        "    test_results.append({'Model': forest_model, 'Fold': fold, 'Precision':  precision_score(test_labels, forest_test_predictions), 'Recall': recall_score(test_labels, forest_test_predictions),\n",
        "                        'Accuracy': accuracy_score(test_labels, forest_test_predictions), 'ROC AUC': roc_auc_score(test_labels, forest_test_probabilities)})\n",
        "    \n",
        "    # Plot ROC curve\n",
        "    #plot_roc(forest_test_probabilities, test_labels, 'Random Forest', fold)\n",
        "\n",
        "\n",
        "    # KNN \n",
        "    KNN_model, knn_score = KNN(training_values_chosen, training_labels)\n",
        "    print(f\"Fold {fold} - KNN Score: {knn_score['test_accuracy'].mean()}\")\n",
        "    #accuracies_knn.append(knn_score['test_accuracy'].mean())\n",
        "    # Append to cross validation training scores\n",
        "    cross_val_results.append({'Model': KNN_model, 'Fold': fold, 'Precision': knn_score['test_precision'].mean(), 'Recall': knn_score['test_recall'].mean(), 'Accuracy': knn_score['test_accuracy'].mean(), 'ROC AUC': knn_score['test_roc_auc'].mean()})\n",
        "\n",
        "    # Predict on the test data\n",
        "    knn_test_predictions = KNN_model.predict(test_values)\n",
        "    knn_test_probabilities = KNN_model.predict_proba(test_values)[:, 1]\n",
        "\n",
        "    # Calculate metrics of test data\n",
        "    test_results.append({'Model': KNN_model, 'Fold': fold, 'Precision':  precision_score(test_labels, knn_test_predictions), 'Recall': recall_score(test_labels, knn_test_predictions),\n",
        "                        'Accuracy': accuracy_score(test_labels, knn_test_predictions), 'ROC AUC': roc_auc_score(test_labels, knn_test_probabilities)})\n",
        "    \n",
        "    # Plot ROC curve\n",
        "    #plot_roc(knn_test_probabilities, test_labels, 'KNN', fold)\n",
        "\n",
        "\n",
        "    # SVM\n",
        "    SVM_model, svm_score = SVM(training_values_chosen, training_labels)\n",
        "    print(f\"Fold {fold} - SVM Score: {svm_score['test_accuracy'].mean()}\")\n",
        "    #accuracies_SVM.append(svm_score['test_accuracy'].mean())\n",
        "    # Append to cross validation training scores\n",
        "    cross_val_results.append({'Model': SVM_model, 'Fold': fold, 'Precision': svm_score['test_precision'].mean(), 'Recall': svm_score['test_recall'].mean(), 'Accuracy': svm_score['test_accuracy'].mean(), 'ROC AUC': svm_score['test_roc_auc'].mean()})\n",
        "\n",
        "    # Predict on the test data\n",
        "    svm_test_predictions = SVM_model.predict(test_values)\n",
        "    svm_test_probabilities = SVM_model.predict_proba(test_values)[:, 1]\n",
        "\n",
        "    # Calculate metrics of test data\n",
        "    test_results.append({'Model': SVM_model, 'Fold': fold, 'Precision':  precision_score(test_labels, svm_test_predictions), 'Recall': recall_score(test_labels, svm_test_predictions),\n",
        "                        'Accuracy': accuracy_score(test_labels, svm_test_predictions), 'ROC AUC': roc_auc_score(test_labels, svm_test_probabilities)})\n",
        "    \n",
        "    # Plot ROC curve\n",
        "    #plot_roc(svm_test_probabilities, test_labels, 'SVM', fold)\n",
        "   \n",
        "    # This code was used to plot the accuracies of different classifiers as a function of the k selected features\n",
        "    \"\"\"\n",
        "    # Plot the accuracies for different classifiers as a function of k\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    plt.plot(range(1, 50, 2), accuracies_logit, label='Logistic Regression', marker='o')\n",
        "    plt.plot(range(1, 50, 2), accuracies_forest, label='Random Forest', marker='s')\n",
        "    plt.plot(range(1, 50, 2), accuracies_knn, label='KNN', marker='^')\n",
        "    plt.plot(range(1, 50, 2), accuracies_SVM, label='SVM', marker='x')\n",
        "\n",
        "    plt.xlabel('k (Number of Features Selected)')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Classifier Accuracies as a Function of k')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \"\"\"\n",
        "\n",
        "# Convert the results list to a dataframe\n",
        "results_df = pd.DataFrame(cross_val_results)\n",
        "results_test_df = pd.DataFrame(test_results)\n",
        "\n",
        "# Save the results to Excel files\n",
        "results_df.to_excel('cross_val_results.xlsx', index=False)\n",
        "results_test_df.to_excel('test_results.xlsx', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
